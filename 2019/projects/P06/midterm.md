---
layout: page
mathjax: true
permalink: /2019/projects/p06/midterm/
---

## 项目进展报告

### 数据获取及预处理

#### 数据来源

所有数据从bilibili主站直接爬取，通过分析网页中数据加载时的API来源获取相关信息，对应的API与信息如下：

| API                                                          | 信息         |
| :----------------------------------------------------------- | ------------ |
| http://bangumi.bilibili.com/media/web_api/search/result      | 番剧列表     |
| https://www.bilibili.com/bangumi/media/md%s/                 | 番剧详细信息 |
| https://api.bilibili.com/x/relation/followers?vmid=%s&pn=1&ps=50&order=desc | 用户粉丝列表 |
| https://api.bilibili.com/x/relation/followings?vmid=%s&pn=1&ps=50&order=desc | 用户关注列表 |
| https://api.bilibili.com/x/space/acc/info?mid=%s             | 用户信息     |
| https://api.bilibili.com/x/relation/stat?vmid=%s             | 用户特征信息 |
| https://api.bilibili.com/x/space/upstat?mid=%s               | 用户投稿信息 |
| https://api.bilibili.com/x/space/bangumi/follow/list?type=1&pn=%s&ps=50&vmid=%s | 番剧收藏列表 |



#### 技术框架

| 框架/语言  | 版本信息 | 用途               |
| ---------- | -------- | ------------------ |
| python     | 3.7.0    | 实现语言           |
| scrapy     | 1.6.0    | 爬虫框架           |
| sqlalchemy | 1.3.2    | orm工具            |
| alembic    | 1.0.8    | 数据库版本管理工具 |



#### 技术要点

* 网站反爬措施
  1. 针对`bilibili`的反爬措施，除去简单的使用`fake-useragent`进行替换以外，还另外构建一个简单爬虫，从各免费代理网站上爬取并维护IP池，当发送爬取信息请求时，从IP池中获取代理IP进行，以防当爬取速度过快时，本机IP被封锁的风险。
  2. 另外`scrapy`中缺少符合要求的`proxy`中间件，所以自行实现`scrapy`中的`middleware`部分。
  3. 通过API中的参数推断，突破对访问列表的限制（原始只能访问前200记录，修改后可访问500条）。
  4. 可分布式爬取。

* 数据存储部分
  1. `scrapy`框架中，数据存储偏向于`orm`类型，所以数据存储上，为了更好的兼容，使用了`sqlalchemy`来定义管理数据表结构，但是`sqlalchemy`缺少完善的版本管理工具，所以使用`alembic`提供管理。
  2. 数据的`pipeline`部分与`model`部分在原框架中只能一一对应，为了避免重复性工作，通过`python`的反射机制实现`pipeline`的一对多方法。
  3. 用户番剧收藏信息存在`redis`数据库中，可以用户爬取过程中的去重操作，其他信息存在`mariadb`中。



#### 数据处理

数据预处理过程中，设置以下规则对数据进行操作：

1. 数据去重
2. 对于用户等级小于2级的用户，不记录
3. 对于处于小黑屋状态的用户，不记录
4. 对于不开放番剧收藏的用户，不记录



#### 困难

大作业的完成过程中，由于我对数据库的不安全设置，导致数据被黑客清空，并索要酬金，后续重新爬取了相关数据，导致后续工作有延迟。

![](https://ws1.sinaimg.cn/large/005J7jqOly1g4moosjbjkj30zd0qygoi.jpg)



### 数据分析与可视化

* 用户开放信息占比

![](https://ws1.sinaimg.cn/large/005J7jqOly1g4mp808k2zj309e056dfu.jpg)

* 用户等级占比

![](https://ws1.sinaimg.cn/large/005J7jqOly1g4mpjnwx5dj306t05m74c.jpg)

* 用户观看番剧占比

  ![](https://ws1.sinaimg.cn/large/005J7jqOly1g4mpvmkowaj308t069glt.jpg)

* 番剧类型占比

  ![](https://ws1.sinaimg.cn/large/005J7jqOly1g4mqwnets2j30o00803yw.jpg)

### 模型选取

1. 首先基于用户的番剧收藏记录进行关联规则挖掘，再根据挖掘到的关联规则及番剧的其他特征进行番剧推荐。
2. 关联规则挖掘算法主要有两种，分别是Apriori算法和FP-Growth算法。通过学习，FP-Growth算法的效率要高于Apriori算法，因此我们选择FP-Growth算法进行关联规则挖掘。
3. 数据集被划分为9000条训练数据和1000条测试数据。其中训练数据用户挖掘关联规则、优化推荐算法，测试数据用户评估推荐的准确率。
4. 通过不断调整参数，我们发现当支持度设为7%时，可以挖掘到446条频繁项集，在此基础上，有261条关联规则的置信度大于60%。由于我们爬取到的番剧有3000多个，因此7%的支持度虽然很低，但也意味着每个频繁项集都至少出现了210次。
5. 当我们获取了所有的关联规则之后，其实已经可以根据用户的番剧收藏记录进行番剧推荐了。针对每一个用户的收藏记录，将可用的关联规则按置信度进行排序，选择置信度最高的关联规则进行推荐。我们在1000条测试数据上进行了推荐准确率的评估。



### 挖掘实验的结果

根据用户的排名、账号等级、vip等级，对用户的番剧收藏记录数据集进行加权扩充后，再进行评估测试。
分别对前100条规则、第100到200条规则、第200到300条规则、全部规则进行评估结果如下：

|规则范围		|平均准确率			|
|---------------|------------------|
|前100条规则		|0.8567302328664756|
|第100到200条规则|0.7807110490250396|
|第200到300条规则|0.73296587114293|
|全部规则		|0.7149250788211877|

发现使用靠近前面的规则进行推荐，平均准确率较高，证明了使用关联规则的置信度对规则进行排名有一定的优化效果。

### 存在的问题

1. 推荐的准确率不够高
2. 没有对挖掘及对推荐的结果进行很好的可视化展示



### 下一步工作

1. 在选择使用哪一条关联规则进行推荐时，不再将置信度作为唯一的标准。而应该将番剧的点赞数量、评分、Tag，以及番剧的声优、导演、画师阵容都纳入考虑范围。将置信度和番剧的各种属性分别设置权重，再对关联规则进行排序，例如：如果该关联规则的前项和后项的番剧有着同一个Tag或同一个声优、导演，那么该条关联规则将大概率会被优先推荐。从而提高推荐的准确率。

2. 将在更新了推荐算法之后，对推荐结果的准确率重新进行评估。并可视化地对比两次挖掘的效果。

   